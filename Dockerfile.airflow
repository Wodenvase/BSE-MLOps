# Dockerfile for Airflow with SENSEX Data Pipeline Support
FROM apache/airflow:2.7.3-python3.9

# Set environment variables
ENV AIRFLOW_HOME=/opt/airflow
ENV PYTHONPATH="${PYTHONPATH}:${AIRFLOW_HOME}/src"

USER root

# Install system dependencies for data science, MLOps, and DVC
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    python3-dev \
    libffi-dev \
    libssl-dev \
    curl \
    build-essential \
    git \
    wget \
    unzip \
    && rm -rf /var/lib/apt/lists/*

USER airflow

# Copy requirements
COPY requirements.txt /opt/airflow/

# Install Python packages
RUN pip install --no-cache-dir -r /opt/airflow/requirements.txt

# Install additional packages for SENSEX forecasting and DVC
RUN pip install --no-cache-dir \
    scikit-learn==1.3.0 \
    tensorflow==2.13.0 \
    keras==2.13.1 \
    lightgbm==4.0.0 \
    xgboost==1.7.6 \
    mlflow==2.7.1 \
    optuna==3.3.0 \
    plotly==5.15.0 \
    streamlit==1.26.0 \
    apache-airflow-providers-postgres==5.6.0 \
    apache-airflow-providers-celery==3.3.0 \
    dvc[gdrive]==3.25.0 \
    google-auth==2.23.0 \
    google-auth-oauthlib==1.0.0 \
    google-auth-httplib2==0.1.0 \
    PyDrive2==1.17.0

# Copy project files
COPY --chown=airflow:root . /opt/airflow/

# Create necessary directories with proper structure
RUN mkdir -p \
    /opt/airflow/data/raw \
    /opt/airflow/data/processed \
    /opt/airflow/data/temp \
    /opt/airflow/models \
    /opt/airflow/logs \
    /opt/airflow/src/data \
    /opt/airflow/src/models \
    /opt/airflow/src/utils \
    /opt/airflow/.dvc/cache

# Set working directory
WORKDIR ${AIRFLOW_HOME}
